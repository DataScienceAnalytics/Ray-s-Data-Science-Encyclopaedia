{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'><img src='../Pierian_Data_Logo.png'/></a>\n",
    "___\n",
    "<center><em>Copyright Pierian Data</em></center>\n",
    "<center><em>For more information, visit us at <a href='http://www.pieriandata.com'>www.pieriandata.com</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SARIMAX\n",
    "\n",
    "## Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors\n",
    "So far the models we've looked at consider past values of a dataset and past errors to determine future trends, seasonality and forecasted values. We look now to models that encompass these non-seasonal (p,d,q) and seasonal (P,D,Q,m) factors, but introduce the idea that external factors (environmental, economic, etc.) can also influence a time series, and be used in forecasting.\n",
    "\n",
    "<div class=\"alert alert-info\"><h3>Related Functions:</h3>\n",
    "<tt><strong>\n",
    "<a href='https://www.statsmodels.org/stable/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html'>sarimax.SARIMAX</a></strong><font color=black>(endog[, exog, order, …])</font>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>\n",
    "<strong><a href='https://www.statsmodels.org/stable/generated/statsmodels.tsa.vector_ar.var_model.VARResults.html'>sarimax.SARIMAXResults</a></strong><font color=black>(model, params, …[, …])</font>&nbsp;&nbsp;Class to hold results from fitting a SARIMAX model.</tt>\n",
    "\n",
    "<h3>For Further Reading:</h3>\n",
    "<strong>\n",
    "<a href='https://www.statsmodels.org/stable/statespace.html'>Statsmodels Tutorial:</a></strong>&nbsp;&nbsp;<font color=black>Time Series Analysis by State Space Methods</font><br>\n",
    "<strong>\n",
    "<a href='https://www.statsmodels.org/devel/examples/notebooks/generated/statespace_sarimax_stata.html'>Statsmodels Example:</a></strong>&nbsp;&nbsp;<font color=black>SARIMAX</font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform standard imports and load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install mlrose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import mlrose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.externals.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24728/1267395377.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraphics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsaplots\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_acf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mplot_pacf\u001b[0m \u001b[1;31m# for determining (p,q) orders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtsa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseasonal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseasonal_decompose\u001b[0m      \u001b[1;31m# for ETS Plots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpmdarima\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauto_arima\u001b[0m                              \u001b[1;31m# for determining ARIMA orders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Ignore harmless warnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tsa\\lib\\site-packages\\pmdarima\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m# Stuff we want at top-level\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0marima\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mauto_arima\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mARIMA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0macf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautocorr_plot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpacf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_acf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_pacf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tsa\\lib\\site-packages\\pmdarima\\arima\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mapprox\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0marima\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mwarnings\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tsa\\lib\\site-packages\\pmdarima\\arima\\auto.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoblib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.externals.joblib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Load specific forecasting tools\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf # for determining (p,q) orders\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose      # for ETS Plots\n",
    "from pmdarima import auto_arima                              # for determining ARIMA orders\n",
    "\n",
    "# Ignore harmless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../Data/RestaurantVisitors.csv',index_col='date',parse_dates=True)\n",
    "df.index.freq = 'D'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the data\n",
    "For this section we've built a Restaurant Visitors dataset that was inspired by a <a href='https://www.kaggle.com/c/recruit-restaurant-visitor-forecasting'>recent Kaggle competition</a>. The data considers daily visitors to four restaurants located in the United States, subject to American holidays. For the exogenous variable we'll see how holidays affect patronage. The dataset contains 478 days of restaurant data, plus an additional 39 days of holiday data for forecasting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that even though the restaurant visitor columns contain integer data, they appear as floats. This is because the bottom of the dataframe has 39 rows of NaN data to accommodate the extra holiday data we'll use for forecasting, and pandas won't allow NaN's as integers. We could leave it like this, but since we have to drop NaN values anyway, let's also convert the columns to dtype int64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.dropna()\n",
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dtype of selected columns\n",
    "cols = ['rest1','rest2','rest3','rest4','total']\n",
    "for col in cols:\n",
    "    df1[col] = df1[col].astype(int)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title='Restaurant Visitors'\n",
    "ylabel='Visitors per day'\n",
    "xlabel='' # we don't really need a label here\n",
    "\n",
    "ax = df1['total'].plot(figsize=(16,5),title=title)\n",
    "ax.autoscale(axis='x',tight=True)\n",
    "ax.set(xlabel=xlabel, ylabel=ylabel);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at holidays\n",
    "Rather than prepare a separate plot, we can use matplotlib to shade holidays behind our restaurant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "title='Restaurant Visitors'\n",
    "ylabel='Visitors per day'\n",
    "xlabel='' # we don't really need a label here\n",
    "\n",
    "ax = df1['total'].plot(figsize=(16,5),title=title)\n",
    "ax.autoscale(axis='x',tight=True)\n",
    "ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "for x in df1.query('holiday==1').index:       # for days where holiday == 1\n",
    "    ax.axvline(x=x, color='k', alpha = 0.3);  # add a semi-transparent grey line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an ETS Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = seasonal_decompose(df1['total'])\n",
    "result.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for stationarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adf_test(series,title=''):\n",
    "    \"\"\"\n",
    "    Pass in a time series and an optional title, returns an ADF report\n",
    "    \"\"\"\n",
    "    print(f'Augmented Dickey-Fuller Test: {title}')\n",
    "    result = adfuller(series.dropna(),autolag='AIC') # .dropna() handles differenced data\n",
    "    \n",
    "    labels = ['ADF test statistic','p-value','# lags used','# observations']\n",
    "    out = pd.Series(result[0:4],index=labels)\n",
    "\n",
    "    for key,val in result[4].items():\n",
    "        out[f'critical value ({key})']=val\n",
    "        \n",
    "    print(out.to_string())          # .to_string() removes the line \"dtype: float64\"\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(\"Strong evidence against the null hypothesis\")\n",
    "        print(\"Reject the null hypothesis\")\n",
    "        print(\"Data has no unit root and is stationary\")\n",
    "    else:\n",
    "        print(\"Weak evidence against the null hypothesis\")\n",
    "        print(\"Fail to reject the null hypothesis\")\n",
    "        print(\"Data has a unit root and is non-stationary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_test(df1['total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run <tt>pmdarima.auto_arima</tt> to obtain recommended orders\n",
    "This may take awhile as there are a lot of combinations to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SARIMA Orders we set seasonal=True and pass in an m value\n",
    "auto_arima(df1['total'],seasonal=True,m=7).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! This provides an ARIMA Order of (1,0,0) and a seasonal order of (2,0,0,7) Now let's train & test the SARIMA model, evaluate it, then compare the result to a model that uses an exogenous variable.\n",
    "### Split the data into train/test sets\n",
    "We'll assign 42 days (6 weeks) to the test set so that it includes several holidays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set four weeks for testing\n",
    "train = df1.iloc[:436]\n",
    "test = df1.iloc[436:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a SARIMA(1,0,0)(2,0,0,7) Model\n",
    "NOTE: To avoid a <tt>ValueError: non-invertible starting MA parameters found</tt> we're going to set <tt>enforce_invertibility</tt> to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train['total'],order=(1,0,0),seasonal_order=(2,0,0,7),enforce_invertibility=False)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predicted values\n",
    "start=len(train)\n",
    "end=len(train)+len(test)-1\n",
    "predictions = results.predict(start=start, end=end, dynamic=False).rename('SARIMA(1,0,0)(2,0,0,7) Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing <tt>dynamic=False</tt> means that forecasts at each point are generated using the full history up to that point (all lagged values).\n",
    "\n",
    "For more information on these arguments visit https://www.statsmodels.org/stable/generated/statsmodels.tsa.arima_model.ARIMAResults.predict.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions against known values\n",
    "title='Restaurant Visitors'\n",
    "ylabel='Visitors per day'\n",
    "xlabel=''\n",
    "\n",
    "ax = test['total'].plot(legend=True,figsize=(12,6),title=title)\n",
    "predictions.plot(legend=True)\n",
    "ax.autoscale(axis='x',tight=True)\n",
    "ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "for x in test.query('holiday==1').index: \n",
    "    ax.axvline(x=x, color='k', alpha = 0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tools.eval_measures import mse,rmse\n",
    "\n",
    "error1 = mse(test['total'], predictions)\n",
    "error2 = rmse(test['total'], predictions)\n",
    "\n",
    "print(f'SARIMA(1,0,0)(2,0,0,7) MSE Error: {error1:11.10}')\n",
    "print(f'SARIMA(1,0,0)(2,0,0,7) RMSE Error: {error2:11.10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now add the exog variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(train['total'],exog=train['holiday'],order=(1,0,0),seasonal_order=(2,0,0,7),enforce_invertibility=False)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predicted values\n",
    "start=len(train)\n",
    "end=len(train)+len(test)-1\n",
    "exog_forecast = test[['holiday']]  # requires two brackets to yield a shape of (35,1)\n",
    "predictions = results.predict(start=start, end=end, exog=exog_forecast).rename('SARIMAX(1,0,0)(2,0,0,7) Predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot predictions against known values\n",
    "title='Restaurant Visitors'\n",
    "ylabel='Visitors per day'\n",
    "xlabel=''\n",
    "\n",
    "ax = test['total'].plot(legend=True,figsize=(12,6),title=title)\n",
    "predictions.plot(legend=True)\n",
    "ax.autoscale(axis='x',tight=True)\n",
    "ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "for x in test.query('holiday==1').index: \n",
    "    ax.axvline(x=x, color='k', alpha = 0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the exogenous variable (holidays) had a positive impact on the forecast by raising predicted values at 3/17, 4/14, 4/16 and 4/17! Let's compare evaluations:\n",
    "### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print values from SARIMA above\n",
    "print(f'SARIMA(1,0,0)(2,0,0,7) MSE Error: {error1:11.10}')\n",
    "print(f'SARIMA(1,0,0)(2,0,0,7) RMSE Error: {error2:11.10}')\n",
    "print()\n",
    "\n",
    "error1x = mse(test['total'], predictions)\n",
    "error2x = rmse(test['total'], predictions)\n",
    "\n",
    "# Print new SARIMAX values\n",
    "print(f'SARIMAX(1,0,0)(2,0,0,7) MSE Error: {error1x:11.10}')\n",
    "print(f'SARIMAX(1,0,0)(2,0,0,7) RMSE Error: {error2x:11.10}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain the model on the full data, and forecast the future\n",
    "We're going to forecast 39 days into the future, and use the additional holiday data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SARIMAX(df1['total'],exog=df1['holiday'],order=(1,0,0),seasonal_order=(2,0,0,7),enforce_invertibility=False)\n",
    "results = model.fit()\n",
    "exog_forecast = df[478:][['holiday']]\n",
    "fcast = results.predict(len(df1),len(df1)+38,exog=exog_forecast).rename('SARIMAX(1,0,0)(2,0,0,7) Forecast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the forecast alongside historical values\n",
    "title='Restaurant Visitors'\n",
    "ylabel='Visitors per day'\n",
    "xlabel=''\n",
    "\n",
    "ax = df1['total'].plot(legend=True,figsize=(16,6),title=title)\n",
    "fcast.plot(legend=True)\n",
    "ax.autoscale(axis='x',tight=True)\n",
    "ax.set(xlabel=xlabel, ylabel=ylabel)\n",
    "for x in df.query('holiday==1').index: \n",
    "    ax.axvline(x=x, color='k', alpha = 0.3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
